{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Single Node on MovieLens (Python, CPU)\n",
    "\n",
    "In this example, we will walk through each step of the Simple Algorithm for Recommendation (SAR) algorithm using a Python single-node implementation.\n",
    "\n",
    "SAR is a fast, scalable, adaptive algorithm for personalized recommendations based on user transaction history. It is powered by understanding the similarity between items, and recommending similar items to those a user has an existing affinity for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 SAR algorithm\n",
    "\n",
    "The following figure presents a high-level architecture of SAR. \n",
    "\n",
    "At a very high level, two intermediate matrices are created and used to generate a set of recommendation scores:\n",
    "\n",
    "- An item similarity matrix $S$ estimates item-item relationships.\n",
    "- An affinity matrix $A$ estimates user-item relationships.\n",
    "\n",
    "Recommendation scores are then created by computing the matrix multiplication $A\\times S$.\n",
    "\n",
    "Optional steps (e.g. \"time decay\" and \"remove seen items\") are described in the details below.\n",
    "\n",
    "<img src=\"https://recodatasets.blob.core.windows.net/images/sar_schema.svg?sanitize=true\">\n",
    "\n",
    "### 1.1 Compute item co-occurrence and item similarity\n",
    "\n",
    "SAR defines similarity based on item-to-item co-occurrence data. Co-occurrence is defined as the number of times two items appear together for a given user. We can represent the co-occurrence of all items as a $m\\times m$ matrix $C$, where $c_{i,j}$ is the number of times item $i$ occurred with item $j$, and $m$ is the total number of items.\n",
    "\n",
    "The co-occurence matric $C$ has the following properties:\n",
    "\n",
    "- It is symmetric, so $c_{i,j} = c_{j,i}$\n",
    "- It is nonnegative: $c_{i,j} \\geq 0$\n",
    "- The occurrences are at least as large as the co-occurrences. I.e., the largest element for each row (and column) is on the main diagonal: $\\forall(i,j) C_{i,i},C_{j,j} \\geq C_{i,j}$.\n",
    "\n",
    "Once we have a co-occurrence matrix, an item similarity matrix $S$ can be obtained by rescaling the co-occurrences according to a given metric. Options for the metric include `Jaccard`, `lift`, and `counts` (meaning no rescaling).\n",
    "\n",
    "\n",
    "If $c_{ii}$ and $c_{jj}$ are the $i$th and $j$th diagonal elements of $C$, the rescaling options are:\n",
    "\n",
    "- `Jaccard`: $s_{ij}=\\frac{c_{ij}}{(c_{ii}+c_{jj}-c_{ij})}$\n",
    "- `lift`: $s_{ij}=\\frac{c_{ij}}{(c_{ii} \\times c_{jj})}$\n",
    "- `counts`: $s_{ij}=c_{ij}$\n",
    "\n",
    "In general, using `counts` as a similarity metric favours predictability, meaning that the most popular items will be recommended most of the time. `lift` by contrast favours discoverability/serendipity: an item that is less popular overall but highly favoured by a small subset of users is more likely to be recommended. `Jaccard` is a compromise between the two.\n",
    "\n",
    "\n",
    "### 1.2 Compute user affinity scores\n",
    "\n",
    "The affinity matrix in SAR captures the strength of the relationship between each individual user and the items that user has already interacted with. SAR incorporates two factors that can impact users' affinities: \n",
    "\n",
    "- It can consider information about the **type** of user-item interaction through differential weighting of different events (e.g. it may weigh events in which a user rated a particular item more heavily than events in which a user viewed the item).\n",
    "- It can consider information about **when** a user-item event occurred (e.g. it may discount the value of events that take place in the distant past.\n",
    "\n",
    "Formalizing these factors produces us an expression for user-item affinity:\n",
    "\n",
    "$$a_{ij}=\\sum_k w_k \\left(\\frac{1}{2}\\right)^{\\frac{t_0-t_k}{T}} $$\n",
    "\n",
    "where the affinity $a_{ij}$ for user $i$ and item $j$ is the weighted sum of all $k$ events involving user $i$ and item $j$. $w_k$ represents the weight of a particular event, and the power of 2 term reflects the temporally-discounted event. The $(\\frac{1}{2})^n$ scaling factor causes the parameter $T$ to serve as a half-life: events $T$ units before $t_0$ will be given half the weight as those taking place at $t_0$.\n",
    "\n",
    "Repeating this computation for all $n$ users and $m$ items results in an $n\\times m$ matrix $A$. Simplifications of the above expression can be obtained by setting all the weights equal to 1 (effectively ignoring event types), or by setting the half-life parameter $T$ to infinity (ignoring transaction times).\n",
    "\n",
    "### 1.3 Remove seen item\n",
    "\n",
    "Optionally we remove items which have already been seen in the training set, i.e. don't recommend items which have been previously bought by the user again.\n",
    "\n",
    "### 1.4 Top-k item calculation\n",
    "\n",
    "The personalized recommendations for a set of users can then be obtained by multiplying the affinity matrix ($A$) by the similarity matrix ($S$). The result is a recommendation score matrix, where each row corresponds to a user, each column corresponds to an item, and each entry corresponds to a user / item pair. Higher scores correspond to more strongly recommended items.\n",
    "\n",
    "It is worth noting that the complexity of recommending operation depends on the data size. SAR algorithm itself has $O(n^3)$ complexity. Therefore the single-node implementation is not supposed to handle large dataset in a scalable manner. Whenever one uses the algorithm, it is recommended to run with sufficiently large memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 SAR single-node implementation\n",
    "\n",
    "The SAR implementation illustrated in this notebook was developed in Python, primarily with Python packages like `numpy`, `pandas`, and `scipy` which are commonly used in most of the data analytics / machine learning tasks. Details of the implementation can be found in [Recommenders/reco_utils/recommender/sar/sar_singlenode.py](../../reco_utils/recommender/sar/sar_singlenode.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 SAR single-node based movie recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "Pandas version: 0.25.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load Data\n",
    "\n",
    "SAR is intended to be used on interactions with the following schema:\n",
    "`<User ID>, <Item ID>, <Time>`. \n",
    "\n",
    "Each row represents a single interaction between a user and an item. These interactions might be different types of events on an e-commerce website, such as a user clicking to view an item, adding it to a shopping basket, following a recommendation link, and so on. \n",
    "\n",
    "The MovieLens dataset is well formatted interactions of Users providing Ratings to Movies (movie ratings are used as the event weight) - we will use it for the rest of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "data_type = '/synthetic' #original or synthetic\n",
    "data_path = data_dir + data_type\n",
    "review_ratio = .5\n",
    "n_users = 10\n",
    "n_recipes_per_cuisine = 10\n",
    "\n",
    "#review_fn = '/recipe_reviews.csv'\n",
    "#features_fn = '/recipe_features.csv'\n",
    "\n",
    "review_fn = '/reviews/{}_users_{}_reviewratio.csv'.format(n_users, int(review_ratio*100))\n",
    "features_fn = '/recipes/cuisine_size_{}.csv'.format(n_recipes_per_cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(data_path + review_fn)# encoding = \"ISO-8859-1\",delimiter=\"|\")\n",
    "features = pd.read_csv(data_path + features_fn)#,encoding = \"ISO-8859-1\",delimiter=\"|\")\n",
    "\n",
    "# only keep recipes with reviews\n",
    "features = pd.merge(features, data, left_on='recipe_id', right_on='recipe_id', how=\"inner\")\n",
    "features = features[[\"recipe_id\", \"cuisine\", \"clean_ingredients\"]]\n",
    "features = features.drop_duplicates().reset_index()\n",
    "features = features[[\"recipe_id\", \"cuisine\", \"clean_ingredients\"]]\n",
    "\n",
    "# Convert ingredients column to list\n",
    "features[\"clean_ingredients\"] = features[\"clean_ingredients\"].apply(lambda a : a.split(\"+\"))\n",
    "\n",
    "# Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>clean_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pork-Schnitzels-778938</td>\n",
       "      <td>German</td>\n",
       "      <td>[crumbs, chops, pork, bread, panko, flour, egg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Runzas-_Bierocks_-1601298</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, dinner, still, rolls, cabbage, thawed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sausage-Sauerkraut-Sloppy-Joes-1557576</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, rolls, had, ground, sauerkraut, what, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sauerbraten-Beef-in-Gingersnap-Gravy-1540117</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, cookies, cider, spaetzle, meat, bay, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sauerbraten-1340986</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, apple, bottom, cider, bay, cloves, pep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      recipe_id cuisine  \\\n",
       "0                        Pork-Schnitzels-778938  German   \n",
       "1                     Runzas-_Bierocks_-1601298  German   \n",
       "2        Sausage-Sauerkraut-Sloppy-Joes-1557576  German   \n",
       "3  Sauerbraten-Beef-in-Gingersnap-Gravy-1540117  German   \n",
       "4                           Sauerbraten-1340986  German   \n",
       "\n",
       "                                   clean_ingredients  \n",
       "0  [crumbs, chops, pork, bread, panko, flour, egg...  \n",
       "1  [onion, dinner, still, rolls, cabbage, thawed,...  \n",
       "2  [onion, rolls, had, ground, sauerkraut, what, ...  \n",
       "3  [onion, cookies, cider, spaetzle, meat, bay, w...  \n",
       "4  [onion, apple, bottom, cider, bay, cloves, pep...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>evette_cant_get_enough_english_food_984</td>\n",
       "      <td>Sauerbraten-Beef-in-Gingersnap-Gravy-1540117</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>evette_cant_get_enough_english_food_984</td>\n",
       "      <td>Sauerbraten-1500604</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>evette_cant_get_enough_english_food_984</td>\n",
       "      <td>German-Pork-Chops-and-Sauerkraut-AllRecipes-40040</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>evette_cant_get_enough_english_food_984</td>\n",
       "      <td>Sausage-Sauerkraut-Sloppy-Joes-1557576</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>evette_cant_get_enough_english_food_984</td>\n",
       "      <td>Sirloin-Stroganoff-MyRecipes-249593</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 username  \\\n",
       "0           3  evette_cant_get_enough_english_food_984   \n",
       "1           6  evette_cant_get_enough_english_food_984   \n",
       "2           8  evette_cant_get_enough_english_food_984   \n",
       "3           2  evette_cant_get_enough_english_food_984   \n",
       "4           7  evette_cant_get_enough_english_food_984   \n",
       "\n",
       "                                           recipe_id  rating  \n",
       "0       Sauerbraten-Beef-in-Gingersnap-Gravy-1540117     2.0  \n",
       "1                                Sauerbraten-1500604     3.0  \n",
       "2  German-Pork-Chops-and-Sauerkraut-AllRecipes-40040     2.0  \n",
       "3             Sausage-Sauerkraut-Sloppy-Joes-1557576     3.0  \n",
       "4                Sirloin-Stroganoff-MyRecipes-249593     2.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>clean_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>210</td>\n",
       "      <td>21</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Chicken-Meatballs-with-Tomato-Balsamic-Glaze-O...</td>\n",
       "      <td>German</td>\n",
       "      <td>[apple, cabbage, pieces, juice, cloves, briske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                recipe_id cuisine  \\\n",
       "count                                                 210     210   \n",
       "unique                                                210      21   \n",
       "top     Chicken-Meatballs-with-Tomato-Balsamic-Glaze-O...  German   \n",
       "freq                                                    1      10   \n",
       "\n",
       "                                        clean_ingredients  \n",
       "count                                                 210  \n",
       "unique                                                206  \n",
       "top     [apple, cabbage, pieces, juice, cloves, briske...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(data.columns)\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Split the data using the python random splitter provided in utilities:\n",
    "\n",
    "We split the full dataset into a `train` and `test` dataset to evaluate performance of the algorithm against a held-out set not seen during training. Because SAR generates recommendations based on user preferences, all users that are in the test set must also exist in the training set. For this case, we can use the provided `python_stratified_split` function which holds out a percentage (in this case 25%) of items from each user, but ensures all users are in both `train` and `test` datasets. Other options are available in the `dataset.python_splitters` module which provide more control over how the split occurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"col_user\": \"username\",\n",
    "    \"col_item\": \"recipe_id\",\n",
    "    \"col_rating\": \"rating\",\n",
    "    \"col_timestamp\": \"date\",\n",
    "    \"col_prediction\": \"Prediction\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 4)\n",
      "(210, 4)\n"
     ]
    }
   ],
   "source": [
    "train, test = python_stratified_split(data, ratio=0.80, col_user=header[\"col_user\"], col_item=header[\"col_item\"],seed=42)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, for the illustration purpose, the following parameter values are used:\n",
    "\n",
    "|Parameter|Value|Description|\n",
    "|---------|---------|-------------|\n",
    "|`similarity_type`|`jaccard`|Method used to calculate item similarity.|\n",
    "|`time_decay_coefficient`|30|Period in days (term of $T$ shown in the formula of Section 2.2.2)|\n",
    "|`time_now`|`None`|Time decay reference.|\n",
    "|`timedecay_formula`|`True`|Whether time decay formula is used.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V1 (key error)\n",
    "# set log level to INFO\n",
    "\n",
    "#from reco_utils.recommender.sar.sar_singlenode import SARSingleNode\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG, \n",
    "#                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "#model = SARSingleNode(\n",
    "#    recipes=features, #FIX\n",
    "#    similarity_type=\"custom\", \n",
    "#    time_decay_coefficient=30, \n",
    "#    time_now=None, \n",
    "#    timedecay_formula=False, #add recipes to node CAN SET THIS TO TRUE LATER BUT LETS LEAVE IT FOR NOW\n",
    "#    **header\n",
    "#)\n",
    "\n",
    "\n",
    "#model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>clean_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pork-Schnitzels-778938</td>\n",
       "      <td>German</td>\n",
       "      <td>[crumbs, chops, pork, bread, panko, flour, egg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Runzas-_Bierocks_-1601298</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, dinner, still, rolls, cabbage, thawed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sausage-Sauerkraut-Sloppy-Joes-1557576</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, rolls, had, ground, sauerkraut, what, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sauerbraten-Beef-in-Gingersnap-Gravy-1540117</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, cookies, cider, spaetzle, meat, bay, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sauerbraten-1340986</td>\n",
       "      <td>German</td>\n",
       "      <td>[onion, apple, bottom, cider, bay, cloves, pep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>Total-Choice-Spinach-Stuffed-Chicken-995251</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[oil, chicken, virgin, pine, clove, grated, ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>White-whole-wheat-pizza-dough-308605</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[semolina, arthur, instant, yeast, king, cold,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>Gnocchi-with-Cherry-Tomatoes-and-Garlicky-Pank...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[breadcrumbs, potato, pint, cherry, cloves, ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>Tuscan-Herb-Cod-with-Tomatoes-_-Arugula-556649</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[balsamic, pinch, cod, olive, cuisine, sea, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>Healthy-Chicken-Alfredo-Pizza-499474</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[creamy, pizza, olive, dough, parmesan, mozzar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             recipe_id  cuisine  \\\n",
       "0                               Pork-Schnitzels-778938   German   \n",
       "1                            Runzas-_Bierocks_-1601298   German   \n",
       "2               Sausage-Sauerkraut-Sloppy-Joes-1557576   German   \n",
       "3         Sauerbraten-Beef-in-Gingersnap-Gravy-1540117   German   \n",
       "4                                  Sauerbraten-1340986   German   \n",
       "..                                                 ...      ...   \n",
       "205        Total-Choice-Spinach-Stuffed-Chicken-995251  Italian   \n",
       "206               White-whole-wheat-pizza-dough-308605  Italian   \n",
       "207  Gnocchi-with-Cherry-Tomatoes-and-Garlicky-Pank...  Italian   \n",
       "208     Tuscan-Herb-Cod-with-Tomatoes-_-Arugula-556649  Italian   \n",
       "209               Healthy-Chicken-Alfredo-Pizza-499474  Italian   \n",
       "\n",
       "                                     clean_ingredients  \n",
       "0    [crumbs, chops, pork, bread, panko, flour, egg...  \n",
       "1    [onion, dinner, still, rolls, cabbage, thawed,...  \n",
       "2    [onion, rolls, had, ground, sauerkraut, what, ...  \n",
       "3    [onion, cookies, cider, spaetzle, meat, bay, w...  \n",
       "4    [onion, apple, bottom, cider, bay, cloves, pep...  \n",
       "..                                                 ...  \n",
       "205  [oil, chicken, virgin, pine, clove, grated, ol...  \n",
       "206  [semolina, arthur, instant, yeast, king, cold,...  \n",
       "207  [breadcrumbs, potato, pint, cherry, cloves, ol...  \n",
       "208  [balsamic, pinch, cod, olive, cuisine, sea, mu...  \n",
       "209  [creamy, pizza, olive, dough, parmesan, mozzar...  \n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-08 17:44:39,945 INFO     Collecting user affinity matrix\n",
      "2019-12-08 17:44:39,947 INFO     De-duplicating the user-item counts\n",
      "2019-12-08 17:44:39,950 INFO     Creating index columns\n",
      "2019-12-08 17:44:39,955 INFO     Building user affinity sparse matrix\n",
      "2019-12-08 17:44:39,957 INFO     Calculating item co-occurrence\n",
      "2019-12-08 17:44:39,961 INFO     Calculating item similarity\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Beef-Teriyaki-978715'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-6ae5831c2c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mjaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recipe_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"ratings\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clean_ingredients\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/6.s080/meal_recommender/reco_utils_2/recommender/sar/sar_singlenode.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, features, col_itemid, col_weights)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratings'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_cooccurrence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_rating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_feature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ratings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/6.s080/meal_recommender/reco_utils_2/recommender/sar/sar_singlenode.py\u001b[0m in \u001b[0;36mmake_sim_matrix\u001b[0;34m(self, df, col_id, col_sim, f)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mnum_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# case j > i redundant, could stop earlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mindex_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Beef-Teriyaki-978715'"
     ]
    }
   ],
   "source": [
    "#V2\n",
    "# set log level to INFO\n",
    "from reco_utils_2.recommender.sar.sar_singlenode import SARSingleNode\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SARSingleNode(\n",
    "    similarity_type=\"custom\", \n",
    "    time_decay_coefficient=30, \n",
    "    time_now=None, \n",
    "    timedecay_formula=False, #add recipes to node CAN SET THIS TO TRUE LATER BUT LETS LEAVE IT FOR NOW\n",
    "    **header\n",
    ")\n",
    "\n",
    "jaccard = lambda a,b: len(set(a).intersection(set(b)))/len(set(a).union(set(b)))\n",
    "\n",
    "model.fit(train, features, \"recipe_id\", {\"ratings\" : 0.5, \"clean_ingredients\" : (0.5, jaccard)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-08 17:44:42,819 INFO     Calculating recommendation scores\n",
      "2019-12-08 17:44:42,821 INFO     Removing seen items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>chinese_finesser_593</td>\n",
       "      <td>Dhal-Curry-983208</td>\n",
       "      <td>45.245834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chinese_finesser_593</td>\n",
       "      <td>Coddle-Food_com-181592</td>\n",
       "      <td>44.169437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chinese_finesser_593</td>\n",
       "      <td>Greek-Stuffed-Tomatoes-With-Quinoa-And-Black-L...</td>\n",
       "      <td>43.454166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>chinese_finesser_593</td>\n",
       "      <td>Steamed-Scallops-with-Soy-Sauce-and-Garlic-Oil...</td>\n",
       "      <td>42.945831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chinese_finesser_593</td>\n",
       "      <td>Aunt-Bee_s-Swedish-Meatballs-and-Meatloaf-1310633</td>\n",
       "      <td>40.404766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                          recipe_id  \\\n",
       "0  chinese_finesser_593                                  Dhal-Curry-983208   \n",
       "1  chinese_finesser_593                             Coddle-Food_com-181592   \n",
       "2  chinese_finesser_593  Greek-Stuffed-Tomatoes-With-Quinoa-And-Black-L...   \n",
       "3  chinese_finesser_593  Steamed-Scallops-with-Soy-Sauce-and-Garlic-Oil...   \n",
       "4  chinese_finesser_593  Aunt-Bee_s-Swedish-Meatballs-and-Meatloaf-1310633   \n",
       "\n",
       "   Prediction  \n",
       "0   45.245834  \n",
       "1   44.169437  \n",
       "2   43.454166  \n",
       "3   42.945831  \n",
       "4   40.404766  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = model.recommend_k_items(train, remove_seen=True)\n",
    "top_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output from the `recommend_k_items` method generates recommendation scores for each user-item pair, which are shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Cuban-roast-pork-_lechon-asado_-351717</td>\n",
       "      <td>17.189978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Sauerkraut-Chickpea-Flour-Ravioli-_-Spiced-App...</td>\n",
       "      <td>16.549009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Mattar-Paneer-1421128</td>\n",
       "      <td>16.248714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Spanish-rice-with-chicken-299070</td>\n",
       "      <td>15.662280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Mini-Mexican-Meatloaves-1247371</td>\n",
       "      <td>15.110806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Marha-Porkolt---Hungarian-Beef-Paprika-Stew-10...</td>\n",
       "      <td>14.950573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Garlic-lover_s-vegetable-stir-fry-with-eggplan...</td>\n",
       "      <td>14.927403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Steamed-Scallops-with-Soy-Sauce-and-Garlic-Oil...</td>\n",
       "      <td>14.858709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Thai-Garlic-Chili-Shrimp-960660</td>\n",
       "      <td>14.684709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>trang_cant_live_without_american_eatz_522</td>\n",
       "      <td>Daging-Masak-Kicap-_Soy-Sauce-Beef_-497096</td>\n",
       "      <td>14.496032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      username  \\\n",
       "190  trang_cant_live_without_american_eatz_522   \n",
       "191  trang_cant_live_without_american_eatz_522   \n",
       "192  trang_cant_live_without_american_eatz_522   \n",
       "193  trang_cant_live_without_american_eatz_522   \n",
       "194  trang_cant_live_without_american_eatz_522   \n",
       "195  trang_cant_live_without_american_eatz_522   \n",
       "196  trang_cant_live_without_american_eatz_522   \n",
       "197  trang_cant_live_without_american_eatz_522   \n",
       "198  trang_cant_live_without_american_eatz_522   \n",
       "199  trang_cant_live_without_american_eatz_522   \n",
       "\n",
       "                                             recipe_id  Prediction  \n",
       "190             Cuban-roast-pork-_lechon-asado_-351717   17.189978  \n",
       "191  Sauerkraut-Chickpea-Flour-Ravioli-_-Spiced-App...   16.549009  \n",
       "192                              Mattar-Paneer-1421128   16.248714  \n",
       "193                   Spanish-rice-with-chicken-299070   15.662280  \n",
       "194                    Mini-Mexican-Meatloaves-1247371   15.110806  \n",
       "195  Marha-Porkolt---Hungarian-Beef-Paprika-Stew-10...   14.950573  \n",
       "196  Garlic-lover_s-vegetable-stir-fry-with-eggplan...   14.927403  \n",
       "197  Steamed-Scallops-with-Soy-Sauce-and-Garlic-Oil...   14.858709  \n",
       "198                    Thai-Garlic-Chili-Shrimp-960660   14.684709  \n",
       "199         Daging-Masak-Kicap-_Soy-Sauce-Beef_-497096   14.496032  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_k_with_titles = (top_k.join(data[['recipe_id']].drop_duplicates().set_index('recipe_id'), \n",
    "                                on='recipe_id', \n",
    "                                how='inner').sort_values(by=['username', 'Prediction'], ascending=False))\n",
    "display(top_k_with_titles.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate the results\n",
    "\n",
    "It should be known that the recommendation scores generated by multiplying the item similarity matrix $S$ and the user affinity matrix $A$ **DOES NOT** have the same scale with the original explicit ratings in the movielens dataset. That is to say, SAR algorithm is meant for the task of *recommending relevent items to users* rather than *predicting explicit ratings for user-item pairs*. \n",
    "\n",
    "To this end, ranking metrics like precision@k, recall@k, etc., are more applicable to evaluate SAR algorithm. The following illustrates how to evaluate SAR model by using the evaluation functions provided in the `reco_utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all ranking metrics have the same arguments\n",
    "args = [test, top_k]\n",
    "kwargs = dict(col_user='username', \n",
    "              col_item='recipe_id', \n",
    "              col_rating='rating', \n",
    "              col_prediction='Prediction', \n",
    "              relevancy_method='top_k', \n",
    "              k=TOP_K)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Top K:\t\t                                       username  \\\n",
      "0                             american_fan_199   \n",
      "1                             american_fan_199   \n",
      "2                             american_fan_199   \n",
      "3                             american_fan_199   \n",
      "4                             american_fan_199   \n",
      "..                                         ...   \n",
      "195  trang_cant_live_without_american_eatz_522   \n",
      "196  trang_cant_live_without_american_eatz_522   \n",
      "197  trang_cant_live_without_american_eatz_522   \n",
      "198  trang_cant_live_without_american_eatz_522   \n",
      "199  trang_cant_live_without_american_eatz_522   \n",
      "\n",
      "                                             recipe_id  Prediction  \n",
      "0           Daging-Masak-Kicap-_Soy-Sauce-Beef_-497096   14.799720  \n",
      "1                                Mattar-Paneer-1421128   14.012736  \n",
      "2                      Thai-Garlic-Chili-Shrimp-960660   13.252731  \n",
      "3                              Thai-Fried-Rice-1164164   13.231270  \n",
      "4                Corned-Beef-And-Cabbage-TasteOfHome_1   13.188874  \n",
      "..                                                 ...         ...  \n",
      "195  Marha-Porkolt---Hungarian-Beef-Paprika-Stew-10...   14.950573  \n",
      "196  Garlic-lover_s-vegetable-stir-fry-with-eggplan...   14.927403  \n",
      "197  Steamed-Scallops-with-Soy-Sauce-and-Garlic-Oil...   14.858709  \n",
      "198                    Thai-Garlic-Chili-Shrimp-960660   14.684709  \n",
      "199         Daging-Masak-Kicap-_Soy-Sauce-Beef_-497096   14.496032  \n",
      "\n",
      "[200 rows x 3 columns]\n",
      "MAP:\t\t 0.0005494505494505495\n",
      "NDCG:\t\t 0.003668196104968003\n",
      "Precision@K:\t 0.005\n",
      "Recall@K:\t 0.0038461538461538464\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\", \n",
    "      \"Top K:\\t\\t {}\".format(top_k),\n",
    "      \"MAP:\\t\\t {}\".format(eval_map),\n",
    "      \"NDCG:\\t\\t {}\".format(eval_ndcg),\n",
    "      \"Precision@K:\\t {}\".format(eval_precision),\n",
    "      \"Recall@K:\\t {}\".format(eval_recall),sep='\\n')\n",
    "\n",
    "# print(\"Model:\",\n",
    "#       f\"Top K:\\t\\t {TOP_K:f}\",\n",
    "#       f\"MAP:\\t\\t {eval_map:f}\",\n",
    "#       f\"NDCG:\\t\\t {eval_ndcg:f}\",\n",
    "#       f\"Precision@K:\\t {eval_precision:f}\",\n",
    "#       f\"Recall@K:\\t {eval_recall:f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Note SAR is a combinational algorithm that implements different industry heuristics. The followings are references that may be helpful in understanding the SAR logic and implementation. \n",
    "\n",
    "1. Badrul Sarwar, *et al*, \"Item-based collaborative filtering recommendation algorithms\", WWW, 2001.\n",
    "2. Scipy (sparse matrix), url: https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "3. Asela Gunawardana and Guy Shani, \"A survey of accuracy evaluation metrics of recommendation tasks\", The Journal of Machine Learning Research, vol. 10, pp 2935-2962, 2009.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
