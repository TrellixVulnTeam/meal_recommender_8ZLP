{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# GET RECIPES TABLE\n",
    "d = {'allrecipes_id': [154, 223], 'title': [\"pasta\", \"pizza\"], 'link' : ['google.com', 'facebook.com'], \\\n",
    "    'ingredients' : [['flour', 'water'],['flour', 'water', 'tomatoes']], 'path' : [['Main Dish', 'Pizza'], ['Main Dish', 'Pasta']]}\n",
    "recipes = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# GET RATING TABLE\n",
    "d = {'user': [1, 2, 0, 0, 5], 'item': [0, 3, 5, 3, 4], 'rating': [5, 4, 2, 1, 3]}\n",
    "ratings = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# GENERATE ITEM TO ITEM SIMILARITY\n",
    "\n",
    "# GENERATE ITEM TO ITEM SIMILARITY BASED ON RATINGS\n",
    "    \n",
    "    # generate a sparse matrix item_x_ratings with #rows = #items and the #cols = #useful_users containing the respective ratings \n",
    "    # normalize each row by subtracting the mean of all the rows' known ratings from all the known ratings values (leave unknown ratings as zeros)\n",
    "    # sim_rating[i, j] = cosine similarity of row i and j \n",
    "    \n",
    "num_items = len(recipes)\n",
    "sim_rating = np.empty((num_items, num_items), dtype=np.float16)\n",
    "\n",
    "\n",
    "# GENERATE ITEM TO ITEM SIMILARITY BASED ON INGREDIENTS AND PATH\n",
    "\n",
    "    # might have to be more efficient (blocking etc?)\n",
    "    \n",
    "sim_ingredients_path = np.empty((num_items, num_items), dtype=np.float16)\n",
    "for i in range(0, num_items):\n",
    "    for j in range(0, num_items): # case j > i redundant, could stop earlier\n",
    "        jac_ingredients =  jaccard(recipes.loc[i].ingredients, recipes.loc[j].ingredients)\n",
    "        jac_path =  jaccard(recipes.loc[i].path, recipes.loc[j].path)\n",
    "        sim_ingredients_path[i,j] = (jac_ingredients * 3 + jac_path) / 4 # just some combination\n",
    "        \n",
    "        \n",
    "# COMBINE TO GET FINAL ITEM TO ITEM SIMILARITY\n",
    "\n",
    "sim_combines = (sim_rating * 2 + sim_ingredients_path) / 3  # just some combination\n",
    "\n",
    "        \n",
    "# now we can replace compute_cooccurrence_matrix() in recommender/sar/sar_singlenode.py\n",
    "# in the microsoft recommender repo with our own sim_combined and use their sar implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    return len(set(a).intersection(set(b)))/len(set(a).union(set(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
